{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ¿Qué problema se va a resolver?\n",
        "El tema de investigación surgió por la necesidad que tienen las empresas operadoras de taxis de la ciudad de Bogotá, estas vienen presentando una creciente problemática de indisponibilidad de servicios de taxis en sus plataformas, esto suceso ocurre principalmente en algunas zonas u horarios específicos.\n",
        "La empresa Taxis Libres (TL), una de las más grandes operadoras de servicios de taxis de la ciudad, ha empezado a recibir una gran cantidad de inconformidades por partes de los usuarios recurrentes de la plataforma por esta misma causa. Solo en el mes de mayo del 2022 la plataforma recibió alrededor de 1.2 millones de solicitudes de servicios de taxis de los cuales el 57% de esas solicitudes fueron abandonadas o rechazadas, lo que los llevó a analizar qué estaba pasando con la prestación de servicios internamente, en esa revisión realizada durante el mismo periodo de tiempo se obtuvieron las principales causas reportadas en la plataforma y que se listarán a continuación:\n",
        "\n",
        "•\tEl usuario se fue\n",
        "\n",
        "•\tEl vehículo se demoró en llegar\n",
        "\n",
        "•\tEl usuario tomó otro taxi\n",
        "\n",
        "Al identificar las causas de los servicios abandonados y rechazados, la empresa se planteó a resolver la siguiente pregunta al problema presentado.\n",
        "¿Como reducir la alta cantidad de inconformidades de los usuarios recurrentes de la plataforma prediciendo sus comportamientos durante la semana y así programarles sus servicios de forma anticipada?\n",
        "\n",
        "## Objetivo general\n",
        "Diseñar un método para predecir las solicitudes de servicios de los usuarios recurrentes \"de empresas de servicios de\" taxis en la ciudad Bogotá - Colombia, \"mediante\" modelos de ML.\n",
        "\n",
        "\n",
        "Evaluar el desempeño de modelos de ML para predecir\n",
        "las solicitudes de servicios de los usuarios recurrentes de empresas de servicios de taxis en la ciudad Bogotá -  Colombia\n",
        "basados en el comportamiento dentro de la plataforma.\n",
        "\n",
        "## Objetivos específicos (Detallar las actividades)\n",
        "• Revisar la literatura de al menos 10 artículos de proyectos relacionados (pendiente)\n",
        "\n",
        "• Analizar los datos de los últimos 6 meses de servicios de la empresa taxis libres.\n",
        "\n",
        "• Determinar las variables significativas a ser empleadas en los modelos de ML.\n",
        "\n",
        "• Evaluar diferentes modelos de ML para la predicción de solicitudes.\n",
        "\n",
        "## ¿Que solución propone al problema?\n",
        "El diseño de un modelo predictivo de solicitudes de servicios de taxis basados en comportamientos de usuarios recurrentes de plataformas móviles para empresas de transporte\n",
        "\n",
        "## ¿Cómo lo pretende solucionar?\n",
        "Utilizando un modelo de clasificación donde se agrupe la información de los servicios que han tomado los usuarios por días de las semanas y horarios, determinando si en ese día y a esa hora se va a tomar un servicio.\n",
        "\n",
        "## ¿Que resultados que espera obtener?\n",
        "Se espera obtener listado por día de las semanas con todos los horarios del día y un determinador que indique si el servicio se va a tomar o no en ese horario. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zm7tiHiJk80E"
      },
      "source": [
        "### ANALISIS EXPLORATORIO DE DATOS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 323,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbQIiJjPgCYj",
        "outputId": "c8d87048-b445-45ec-8e27-4e604af3a8b7"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Definición de librerías del proyecto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 324,
      "metadata": {
        "id": "9YlqkYPGeDuz"
      },
      "outputs": [],
      "source": [
        "#librerias\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "#from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "#from sklearn.metrics import plot_confusion_matrix\n",
        "from matplotlib.colors import ListedColormap\n",
        "#from mlxtend.plotting import plot_decision_regions\n",
        "#modelos\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.linear_model import Perceptron\n",
        "\n",
        "#from sklearn.metrics import mean_absolute_error\n",
        "#from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "import numpy as np\n",
        "#from numpy import NaN\n",
        "from datetime import datetime, timedelta\n",
        "#from os import name\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yj6GLCBW1jan"
      },
      "source": [
        "Definición de parámetros iniciales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 325,
      "metadata": {
        "id": "GLoQZVku1iMb"
      },
      "outputs": [],
      "source": [
        "TRAIN_WEEK = 6.0\n",
        "TEST_WEEK = 1.0\n",
        "BOGOTA_CODE = 11001\n",
        "HOURS_OF_DAY = 24\n",
        "DAYS_OF_WEEK = 7\n",
        "FORMAT_DATE = '%Y-%m-%d'\n",
        "FORMAT_COMPLETE_DATE = '%Y/%m/%d %H:%M:%S'\n",
        "DATE_START_TRAINIG = pd.to_datetime(\"2022-03-01\", format=FORMAT_DATE)\n",
        "FICHERO_DATA = '../data/SERVICIO_UNIFICADO_2022.parquet.gzip'\n",
        "\n",
        "#Se obtiene la fecha de inicial de entrenamiento\n",
        "last_date_dataset = DATE_START_TRAINIG - timedelta(weeks=TRAIN_WEEK)\n",
        "#Se obtiene la fecha de inicial de entrenamiento\n",
        "first_date_dataset = DATE_START_TRAINIG + timedelta(weeks=TEST_WEEK)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se cargan los datos en el dataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 326,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnMbR7vKA1KO",
        "outputId": "d19dfb19-63d8-4113-dd65-f304764645d8"
      },
      "outputs": [],
      "source": [
        "#Se lee el archivo de un parquet a un dataframe\n",
        "df_taxis = pd.read_parquet(FICHERO_DATA) \n",
        "#Se visualizan los datos\n",
        "print(\"Datos cargados correctamente\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se visualiza la cantidad de servicios en el tiempo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dft = df_taxis.copy()\n",
        "service_date = pd.to_datetime(dft['FECHACOMPLETA'], format=FORMAT_COMPLETE_DATE)\n",
        "#Se crea un nuevo campo con la fecha en formato YYYY-MM-DD\n",
        "dft['FECHA'] = service_date.dt.strftime(FORMAT_DATE)\n",
        "\n",
        "#Eliminamos las columan que no son útiles para el modelo\n",
        "dft = dft.drop(columns=[\"IDCIUDAD\",\"USUARIO\",\"ID\",\"LATITUDDESTINO\",\"LONGITUDDESTINO\",\"LATITUD\",\"LONGITUD\",\"FECHACOMPLETA\",\"ORIGEN\",\"ESTADO\"])\n",
        "#Se eliminan los valores duplicados del dataframe y se ordenan por los campos más relevangtes\n",
        "dft = dft.drop_duplicates().sort_values(by=['FECHA','TELEFONOORIGEN','DIADESEMANA','HORA'])\n",
        "#Se reindexa nuevamente el dataFrame\n",
        "dft = dft.reset_index(drop=True)\n",
        "\n",
        "dft.groupby(['FECHA'])['FECHA'].count().plot(kind='line',stacked=True, fontsize=14, xlabel=\"Mes\", ylabel=\"Cantidad servicios\", figsize=(12,8), title=\"Servicios por periodo\", rot=45)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se filtra el dataset con los valores a utilizar en las pruebas del modelo 8 semanas anteriores y una semana después"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"Se restringe el dataset desde la fecha:{last_date_dataset} - hasta la fecha:{first_date_dataset}\")\n",
        "\n",
        "#Se particiona el dataframe desde la fecha inicial y hasta la fecha final de entrenamiento\n",
        "df_taxis = df_taxis[ (pd.to_datetime(df_taxis['FECHACOMPLETA'], format=FORMAT_DATE) >= last_date_dataset) & (pd.to_datetime(df_taxis['FECHACOMPLETA'], format=FORMAT_DATE) <= first_date_dataset) ]\n",
        "df_taxis = df_taxis.sort_values(by=['FECHACOMPLETA','USUARIO'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visualizamos los tipos de datos del dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_taxis.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_taxis.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualización de datos iniciales"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se validan los datos categoricos de origen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Se visualiza la cantidad por origen\n",
        "plt.figure(figsize=(12,8))\n",
        "sns.histplot(df_taxis['ORIGEN'])\n",
        "plt.xticks(rotation='vertical')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se validan los datos categoricos de estado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Se visualiza la cantidad de servicios por estado\n",
        "plt.figure(figsize=(12,8))\n",
        "sns.histplot(df_taxis['ESTADO'])\n",
        "plt.xticks(rotation='vertical')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se visualizan los datos del dataFrame en un histograma para analizar los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Se require presentar gráfica de histograma por cada columna o datos de dataframe\n",
        "df_taxis.hist(figsize=(20,10))\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-Se limitan los datos a la ciudad de bogotá.\n",
        "\n",
        "-Se limita al canal APP que es por donde se reciben la mayoria de los servicios.\n",
        "\n",
        "-Se limitan los estados a ABANDONADO, CUMPLIDO, CANCELADO Y FINALIZADO que son los validos, el restos son errores del proceso."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Se filtra el dataset solo para la ciudad de bogotá\n",
        "df_taxis = df_taxis[df_taxis[\"IDCIUDAD\"]==BOGOTA_CODE]\n",
        "df_taxis = df_taxis[(df_taxis[\"ORIGEN\"]==\"APP\")]\n",
        "df_taxis = df_taxis[(df_taxis[\"ESTADO\"]==\"ABANDONADO\") | (df_taxis[\"ESTADO\"]==\"CUMPLIDO\") | (df_taxis[\"ESTADO\"]==\"CANCELADO\") | (df_taxis[\"ESTADO\"]==\"FINALIZADO\")]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65CC2tpPmJk5"
      },
      "source": [
        "Se valida cuantos valores nulos tenemos en el dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWgKyA9DmHPO",
        "outputId": "be8d5d42-49c6-4b53-8807-6aea60c62573"
      },
      "outputs": [],
      "source": [
        "#Contar cuantos datos se encuentran nulos\n",
        "df_taxis.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qA9Hmg3dbGmG"
      },
      "source": [
        "Se crean los campos de fecha sin la hora y el día de la semana"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eT6AHEo2bFZg"
      },
      "outputs": [],
      "source": [
        "service_date = pd.to_datetime(df_taxis['FECHACOMPLETA'], format=FORMAT_COMPLETE_DATE)\n",
        "#Se crea un nuevo campo con la fecha en formato YYYY/MM/DD\n",
        "df_taxis['FECHA'] = service_date.dt.strftime(FORMAT_DATE)\n",
        "#Se crea un nuevo campo con el mes\n",
        "df_taxis['MES'] = service_date.dt.month\n",
        "#Se crea un nuevo campo con la fecha en formato YYYY/MM/DD\n",
        "df_taxis['DIADESEMANA'] = service_date.map( lambda x: x.isoweekday() )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se visualizan las corelaciones entre variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,8))\n",
        "sns.heatmap(df_taxis.corr(method='pearson'),annot=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se visualiza un histograma con la cantidad de servicios por estado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_taxis.groupby(['MES','ESTADO'])['ID'].count().unstack('ESTADO').plot(kind='bar',stacked=True, fontsize=14, xlabel=\"Mes\", ylabel=\"Cantidad servicios\", figsize=(12,8), title=\"Servicios por periodo\", rot=0)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se eliminan los datos que no se necesitan para predecir el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Eliminamos las columan que no son útiles para el modelo\n",
        "df_taxis = df_taxis.drop(columns=[\"IDCIUDAD\",\"USUARIO\",\"ID\",\"LATITUDDESTINO\",\"LONGITUDDESTINO\",\"LATITUD\",\"LONGITUD\",\"FECHACOMPLETA\",\"ORIGEN\",\"ESTADO\",\"MES\"])\n",
        "#Se eliminan los valores duplicados del dataframe y se ordenan por los campos más relevangtes\n",
        "df_taxis = df_taxis.drop_duplicates().sort_values(by=['FECHA','TELEFONOORIGEN','DIADESEMANA','HORA'])\n",
        "#Se reindexa nuevamente el dataFrame\n",
        "df_taxis = df_taxis.reset_index(drop=True)\n",
        "#Se visualizan como queda el dataFrame\n",
        "df_taxis.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(12, 4))\n",
        "s_taxis = df_taxis.groupby(['DIADESEMANA','HORA'])['FECHA'].count()\n",
        "s_taxis.plot(ax=ax)\n",
        "_ = ax.set(\n",
        "    title=\"Cantidad de servicios durante la semana\",\n",
        "    xticks=[i * 24 for i in range(7)],\n",
        "    xticklabels=[\"Dom\", \"Lun\", \"Mar\", \"Mie\", \"Jue\", \"Vie\", \"Sab\"],\n",
        "    xlabel=\"Día de la semana\",\n",
        "    ylabel=\"Número de servicvios\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se contabilizan cuantos servicios tiene asignado un teléfono después de eliminar los duplicados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "count_services = df_taxis.loc[:,['TELEFONOORIGEN']].value_counts()\n",
        "count_services"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se observa la distribución de los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Se visualizan los valores de los datos\n",
        "count_services.describe()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se calcula los outliers de los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Se calcula el quartil 25\n",
        "q25 = count_services.quantile(0.25)\n",
        "#Se calcula el quartil 50\n",
        "q50 = count_services.quantile(0.5)\n",
        "#Se calcula el quartil 75\n",
        "q75 = count_services.quantile(0.75)\n",
        "#Se calcula el rango inter quartil\n",
        "iqr = q75 - q25\n",
        "\n",
        "print(f\"El porcentaje del quartil 25: {q25}\")\n",
        "print(f\"El porcentaje del quartil 75: {q75}\")\n",
        "print(f\"El rango inter quartil es: {iqr}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se calcula el umbral de los valores atípicos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Se calcula el umbral de los  valores atípicos\n",
        "outliers_threshold = ( q75 + 3 * iqr )\n",
        "print(f\"El umbral de los valores atípicos es: {outliers_threshold}\")\n",
        "print(f\"La cantidad de valores atípicos son: {sum(count_services > outliers_threshold) }\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se eliminan los outliers de los datos de train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#df_taxis = df_taxis.groupby('TELEFONOORIGEN').filter(lambda x: (x['TELEFONOORIGEN'].count() <= outliers_threshold) & (x['TELEFONOORIGEN'].count() > q75) )\n",
        "df_taxis = df_taxis.groupby('TELEFONOORIGEN').filter(lambda x: (x['TELEFONOORIGEN'].count() > outliers_threshold) )\n",
        "#Se visualizan los datos agrupados por mes para determinar cuantos servicios tomó un usuario\n",
        "#df_taxis.groupby(['MES','TELEFONOORIGEN'])['TELEFONOORIGEN'].count()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se Validan los datos del dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_taxis.loc[:,['TELEFONOORIGEN']].value_counts().describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### VISUALIZACIÓN DE DATOS\n",
        "\n",
        "* Gráfico de dispersión de las variables\n",
        "* Gráfico de distribución de las variables (Baja distribución, Baja predicción)\n",
        "* Gráficas de correlación (Mapa de calor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Se presenta un gráfico general de los datos\n",
        "sns.pairplot(df_taxis)\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se muestra la matriz de correlación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corr_matrix = df_taxis.corr()\n",
        "corr_matrix"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se visualizan las relación entre variables de los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "f, ax = plt.subplots(figsize=(12, 8))\n",
        "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
        "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
        "sns.heatmap(corr_matrix, annot=True, mask = mask, cmap=cmap )\n",
        "plt.title('Relacion entre variables del dataframe',fontsize=20,fontname='serif')\n",
        "plt.ylabel('Y', color='green', fontsize=25)\n",
        "plt.xlabel('X', color='Red', fontsize=25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### EXPERIMENTOS CON DIFERENTES ENTRENAMIENTOS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\"\"\"\n",
        "#Funcion que permite llenar los servicios tomados con 1 y los no tomados con 0\n",
        "def setDataService(data, from_date, to_date):\n",
        "  remaining_days = to_date.date() - from_date.date()\n",
        "  service_array = []\n",
        "  for i in range(remaining_days.days+1):\n",
        "    last_time = from_date + timedelta(days=i)\n",
        "    if last_time.date().isoweekday() == to_date.date().isoweekday():\n",
        "      for hour in range(HOURS_OF_DAY):\n",
        "        #Se filtra por el mismo día de la semana, fecha y hora\n",
        "        df_service = data[(data['DIADESEMANA'] == last_time.isoweekday()) & (data['FECHA'] == last_time.strftime(FORMAT_DATE)) & (data['HORA'] == hour) ].to_numpy()\n",
        "        if len(df_service) > 0:\n",
        "          #Se llena con valor en 1 porqué se encontró un servicio\n",
        "          service_array.append(np.append(df_service, 1))\n",
        "        else:\n",
        "          #Se llena con valor en 0 porqué no se encontró ningún servicio\n",
        "          service_array.append([last_time.isoweekday(),hour,last_time.month,last_time.date().strftime(FORMAT_DATE),0])\n",
        "  return pd.DataFrame(service_array, \n",
        "             columns=np.append(np.array(data.columns.tolist()), 'SERVICIO'))\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#limites de decision\n",
        "def make_meshgrid(X, step=.02):\n",
        "    x = X.iloc[:,0].values\n",
        "    y = X.iloc[:,1].values\n",
        "    x_min, x_max = x.min() - 1, x.max() + 1\n",
        "    y_min, y_max = y.min() - 1, y.max() + 1\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, step), np.arange(y_min, y_max, step))\n",
        "    return xx, yy\n",
        "\n",
        "def plot_contours(ax, clf, X, y, **params):\n",
        "\n",
        "    markers = ('o', 's', '^', 'v', '<')\n",
        "    colors = ('red', 'blue', 'cyan', 'gray')\n",
        "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
        "\n",
        "    xx, yy = make_meshgrid(X)\n",
        "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "\n",
        "    ax.set_xlim(xx.min(), xx.max())\n",
        "    ax.set_ylim(yy.min(), yy.max())\n",
        "\n",
        "    # plot class examples\n",
        "    for idx, cl in enumerate(np.unique(y)):\n",
        "        Z[Z == cl] = idx\n",
        "        ax.scatter(X.loc[y == cl, X.columns[0]], \n",
        "                    X.loc[y == cl, X.columns[1]],\n",
        "                    alpha=0.8, \n",
        "                    c=colors[idx],\n",
        "                    marker=markers[idx],\n",
        "                    label=cl, \n",
        "                    edgecolor='black',\n",
        "                    cmap=cmap,\n",
        "                    s=50)\n",
        "    \n",
        "    ax.legend()\n",
        "    ax.set_ylabel(X.columns[1])\n",
        "    ax.set_xlabel(X.columns[0])\n",
        "    ax.set_title(clf.__class__.__name__)\n",
        "    ax.grid()    \n",
        "    out = ax.contourf(xx, yy, Z, alpha=0.2, cmap=cmap)\n",
        "    \n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#ROC Y AUC\n",
        "def ROC(X, y, model):\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "\n",
        "  clf = OneVsRestClassifier(model)\n",
        "  clf.fit(X_train, y_train)\n",
        "  pred = clf.predict(X_test)\n",
        "  pred_prob = clf.predict_proba(X_test)\n",
        "  pred_prob = np.nan_to_num(pred_prob)\n",
        "\n",
        "  fpr = {}\n",
        "  tpr = {}\n",
        "  thresh ={}\n",
        "\n",
        "  fig, ax = plt.subplots(figsize=(10,8))\n",
        "  colors = ('orange', 'green', 'blue')\n",
        "  \n",
        "  for index, label_ in enumerate(y.unique()):\n",
        "    fpr[label_], tpr[label_], thresh[label_] = roc_curve(y_test, pred_prob[:,index], pos_label=label_) \n",
        "    ax.plot(fpr[label_], tpr[label_], linestyle='--',color=colors[index], label=label_)\n",
        "  \n",
        "  ax.plot([0, 1], [0, 1], linestyle='--',color='red', label='No Skill')\n",
        "  ax.set_title(f'Multiclass ROC curve -  {model.__class__.__name__}')\n",
        "  ax.set_xlabel('False Positive Rate')\n",
        "  ax.set_ylabel('True Positive rate')\n",
        "  ax.grid(True)\n",
        "  plt.show()\n",
        "\n",
        "  return ax.legend(loc='best')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Funcion que permite entrenar el modelo y predecir con los valores de pruebas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predictModel(model, X_train, y_train, X_test):\n",
        "    #A continuación se entrena el modelo\n",
        "    model.fit(X_train, y_train)\n",
        "    #Se crean las predicciones para pruebas\n",
        "    y_pred = model.predict(X_test)\n",
        "    #Se crean las probabilidades para pruebas\n",
        "    y_prob = model.predict_proba(X_test)\n",
        "    return model, y_pred, y_prob"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Función que permite evaluar el modelo de los K vecinos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def knnModel(X_train, y_train, X_test):\n",
        "    #Se aplica el modelo de K vecinos\n",
        "    model = KNeighborsClassifier(n_neighbors=3)\n",
        "    return predictModel(model, X_train, y_train, X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Función que permite evaluar el modelo de perceptrones multi capa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def mlpModel(X_train, y_train, X_test):\n",
        "    #Se aplica el modelo de perceptrones multi capa\n",
        "    model = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(30,30, 30), random_state=1,learning_rate_init=0.001,max_iter=5000)\n",
        "    return predictModel(model, X_train, y_train, X_test)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Función que permite evaluar el modelo de perceptrones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def perModel(X_train, y_train, X_test):\n",
        "    #Se aplica el modelo de perceptrones multi capa\n",
        "    model = Perceptron(eta0=0.1, n_iter_no_change=10, random_state=1)\n",
        "    return predictModel(model, X_train, y_train, X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Función que permite evaluar el modelo de regesión logística"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def lrModel(X_train, y_train, X_test):\n",
        "    #Se aplica el modelo de de regesión logística\n",
        "    model = LogisticRegression(random_state = 1)\n",
        "    return predictModel(model, X_train, y_train, X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Función que permite evaluar el modelo de los arboles aleatorios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def rfcModel(X_train, y_train, X_test):\n",
        "    #Se aplica el modelo de los arboles aleatorios\n",
        "    model = RandomForestClassifier(criterion='gini', max_depth=5, n_estimators=200, class_weight=\"balanced\")\n",
        "    return predictModel(model, X_train, y_train, X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Función que permite evaluar el modelo de máquina de soporte de vectores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def svcModel(X_train, y_train, X_test):\n",
        "    #Se aplica el modelo de máquina de soporte de vectores\n",
        "    model = SVC(kernel='rbf', random_state=1, gamma=0.2, C=1.0, class_weight='balanced')#, class_weight='balanced'\n",
        "    return predictModel(model, X_train, y_train, X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Función que permite evaluar el modelo de los arboles de desiciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def dtcModel(X_train, y_train, X_test,):\n",
        "    #Se aplica el modelo de los arboles de desiciones\n",
        "    model = DecisionTreeClassifier(criterion='gini', max_depth=3, class_weight='balanced')#class_weight={0: 1, 1: 5}\n",
        "    return predictModel(model, X_train, y_train, X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Función que permite evaluar el modelo de gradiente descendente estocástico"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sgdModel(X_train, y_train, X_test,):\n",
        "    #Se aplica el modelo de gradiente descendente estocástico\n",
        "    model =SGDClassifier(loss='huber', random_state=1, max_iter=2000, epsilon=0.1)#loss='hinge'\n",
        "    return predictModel(model, X_train, y_train, X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Función que permite mostrar la visualización de los datos con subplot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def dataVisualization(df_train):\n",
        "    #Se visualiza los datos por columnas de entrenamiento\n",
        "    fig, axes = plt.subplots(1, len(df_train.columns))\n",
        "    fig.set_size_inches(21,6)\n",
        "    for i, column in enumerate(df_train.columns):\n",
        "        sns.histplot(df_train[column], kde=True, ax=axes[i])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Función que permite mostrar la matriz de confusión"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def confusionMatrix(model, y_test, y_pred):\n",
        "  '''\n",
        "  plt.rcParams.update({'font.size': 16})\n",
        "  fig, axes = plt.subplots(figsize=(14, 10))\n",
        "  disp = ConfusionMatrixDisplay.from_estimator(model,\n",
        "                                             y_test,\n",
        "                                             y_pred,\n",
        "                                             display_labels=model.classes_,\n",
        "                                             cmap=plt.cm.Blues,\n",
        "                                             ax=axes\n",
        "                                             )\n",
        "  disp.ax_.set_title(f'Confusion Matrix - {model.__class__.__name__}')\n",
        "  plt.show()\n",
        "  '''\n",
        "  plt.rcParams.update({'font.size': 16})\n",
        "  cm = confusion_matrix(y_test, y_pred, labels=model.classes_)\n",
        "  disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
        "                                display_labels=model.classes_)\n",
        "  disp.plot()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def contoursGrap(model, X, y):\n",
        "    plt.rcParams.update({'font.size': 16})\n",
        "    fig, axes = plt.subplots(figsize=(12, 10))\n",
        "    plot_contours(axes, model, X, y, cmap=plt.cm.coolwarm, alpha=0.5)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Función que permite mostrar los diferentes reportes para comparar los modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def reportClassification(model, X_train, y_train, y_pred, X_test, y_test, model_type):\n",
        "    if model_type == 'LR':\n",
        "        #Se imprimen los coeficientes, intresección y número de coeficientes\n",
        "        print(f\"Coeficientes del modelo: {model.coef_}\\n\")\n",
        "        print(f\"Intresección del modelo: {model.intercept_}\\n\")\n",
        "        print(f\"Número de coeficientes del modelo: {len(model.coef_)}\\n\")\n",
        "    if model_type != 'PR':\n",
        "\n",
        "        if (model_type != 'SVC') & (model_type != 'SGD'):\n",
        "            #\n",
        "            ROC(X_train, y_train, model)\n",
        "        #\n",
        "        contoursGrap(model, X_train, y_train)\n",
        "        #\n",
        "    #Se muestra la matriz de confusión\n",
        "    confusionMatrix(model, y_test, y_pred)\n",
        "    #Se imprime el reporte de clasificación\n",
        "    #print(classification_report(y_test, y_pred))\n",
        "    #mae = mean_absolute_error(y_test, y_pred)\n",
        "    #print(\"MAE:\",(mae))\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Función que permite cálcular la probabilidad de un usuario"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ProbabilisticClassifier(hour, day, data):\n",
        "  data_array = data.to_numpy()\n",
        "  first = pd.to_datetime(data.tail(1).iloc[0,2], format=FORMAT_DATE)\n",
        "  last = pd.to_datetime(data.head(1).iloc[0,2], format=FORMAT_DATE)\n",
        "  remaining_days = first.date() - last.date()\n",
        "  total = 0 \n",
        "  for i in range(remaining_days.days):\n",
        "    last_time = last + timedelta(days=i)\n",
        "    if last_time.isoweekday() == day:\n",
        "      total += 1\n",
        "  total_onset = 0\n",
        "  for row in data_array:\n",
        "    if( ( row[0] == day ) & ( row[1] == hour ) & ( row[3] == 1 ) ):\n",
        "      total_onset += 1\n",
        "  if total > 0:\n",
        "    return total_onset / total\n",
        "  else:\n",
        "    return 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Función que permite evaluar el modelo probabilistico"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def probabilisticModel(data, date_predict):\n",
        "    threshold = 0.5\n",
        "    array_result = []\n",
        "    array_prob = []\n",
        "    for hour in range(HOURS_OF_DAY):\n",
        "        result = ProbabilisticClassifier(hour, date_predict.isoweekday(), data)\n",
        "        array_prob.append(round(result,2) if result >= threshold else 0 )\n",
        "        array_result.append(1 if result >= threshold else 0)\n",
        "    return array_result, array_prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Conversor del codigo a nombre de modelos\n",
        "def modelName(model_type):\n",
        "    if model_type == 'LR':\n",
        "        return 'logistic regression'\n",
        "    elif model_type == 'KNN':\n",
        "        return 'kneighbors'\n",
        "    elif model_type == 'MLP':\n",
        "        return 'multilayer perceptron'\n",
        "    elif model_type == 'RFC':\n",
        "        return 'random forest'\n",
        "    elif model_type == 'SVC':\n",
        "        return 'support vector'\n",
        "    elif model_type == 'SGD':\n",
        "        return 'gradient descent stochastic'\n",
        "    elif model_type == 'DTC':\n",
        "        return 'decision tree'\n",
        "    elif model_type == 'PR':\n",
        "        return 'probabilistic model'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Función para validar si contiene todos los datos en 0\n",
        "def existAllZero(arr):\n",
        "    if len(arr)>0:\n",
        "        for value in arr:\n",
        "            if value != 0:\n",
        "                return False\n",
        "    return True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Funcion que permite rellenar el dataset con los servicios tomados en 1 y los no tomados en 0\n",
        "def setDataService(data, from_date, to_date):\n",
        "  #print(\"From: \",from_date.date())\n",
        "  #print(\"To: \",to_date.date())\n",
        "  remaining_days = to_date.date() - from_date.date()\n",
        "  service_array = []\n",
        "  day_validation = {}\n",
        "  for i in range(remaining_days.days+1):\n",
        "    last_time = from_date + timedelta(days=i)\n",
        "    if last_time.date().isoweekday() == to_date.date().isoweekday():\n",
        "      day_validation[last_time.strftime(FORMAT_DATE)] = 0\n",
        "      for hour in range(HOURS_OF_DAY):\n",
        "        #Se filtra por el mismo día de la semana, fecha y hora\n",
        "        #df_service = data[(data['DIADESEMANA'] == last_time.isoweekday()) & (data['FECHA'] == last_time.date()) & (data['HORA'] == hour) ].to_numpy()\n",
        "        df_service = data[(data['FECHA'].astype(str) == last_time.strftime(FORMAT_DATE)) & (data['HORA'] == hour) ].to_numpy()\n",
        "        if len(df_service) > 0:\n",
        "          #Se llena con valor en 1 porqué se encontró un servicio\n",
        "          service_array.append(np.append(df_service, 1))\n",
        "          day_validation[last_time.strftime(FORMAT_DATE)] += 1\n",
        "        else:\n",
        "          #Se llena con valor en 0 porqué no se encontró ningún servicio\n",
        "          service_array.append([last_time.isoweekday(),hour,last_time.date().strftime(FORMAT_DATE),0])\n",
        "  return pd.DataFrame(service_array, \n",
        "             columns=np.append(np.array(data.columns.tolist()), 'SERVICIO')), day_validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Función que permite probar los diferentes modelos en un rango de tiempo configurado "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "#Función que entrene el modelo y nos devuelva el y_predicted\n",
        "def evaluate_model(phone, data, date_predict, model_type):\n",
        "  #Inicialización de vectores\n",
        "  y_pred = np.empty(0,dtype=int)\n",
        "  y_prob = np.empty(0,dtype=float)\n",
        "  y_test = np.empty(0,dtype=int)\n",
        "\n",
        "  y_result_arr = []\n",
        "  y_prob_arr = []\n",
        "  #Se filtra por el número de teléfono\n",
        "  data = data[data[\"TELEFONOORIGEN\"]==phone].copy()\n",
        "  #Se elimina el teléfono debido a que no es relevante para el modelo\n",
        "  data = data.drop(labels=['TELEFONOORIGEN'], axis=1)\n",
        "  \n",
        "  #Se obtiene la fecha de inicial de entrenamiento\n",
        "  date_first_training = date_predict - timedelta(weeks=TRAIN_WEEK)\n",
        "  \n",
        "  #Se particiona el dataframe desde la fecha inicial y hasta la fecha final de entrenamiento\n",
        "  data = data[ (pd.to_datetime(data['FECHA'], format=FORMAT_DATE) >= date_first_training) & (pd.to_datetime(data['FECHA'], format=FORMAT_DATE) <= date_predict) ]\n",
        "  \n",
        "  #Se obtiene el tamaño de los datos del usuario\n",
        "  tam = len(data)\n",
        "\n",
        "  #Se valida si tiene más de un servicio registrado\n",
        "  if tam > 1:\n",
        "    #Se llenan en 0 las horas de los servicios que no se tomaron por el usuario\n",
        "    data, day_val = setDataService(data, date_first_training, date_predict)\n",
        "    #Se crear el dataframe de entrenamiento desde la fecha inicial hasta la fecha de predicción\n",
        "    train = data[ (pd.to_datetime(data['FECHA'], format=FORMAT_DATE) >= date_first_training) & (pd.to_datetime(data['FECHA'], format=FORMAT_DATE) < date_predict) ]\n",
        "    #Se crear el dataframe de pruebas desde la fecha de predicción hasta una semana adelante\n",
        "    test = data[(pd.to_datetime(data['FECHA'], format=FORMAT_DATE) == date_predict) ]\n",
        "\n",
        "    amout_services = 0\n",
        "    for key, values in day_val.items():\n",
        "      if (date_predict.strftime(FORMAT_DATE) != key) & (values > 0):\n",
        "        amout_services += 1\n",
        "\n",
        "    #Se obtiene el tamaño de los datos del usuario\n",
        "    tam = len(train[train['SERVICIO']==1])\n",
        "    #Se valida si tiene más de un servicio tomado\n",
        "    if amout_services >= 3:\n",
        "      #Datos para probar los modelos\n",
        "      if model_type != 'PR':\n",
        "        train = train.loc[:,['DIADESEMANA','HORA','SERVICIO']]\n",
        "        test = test.loc[:,['DIADESEMANA','HORA','SERVICIO']]\n",
        "      else:\n",
        "        train = train.loc[:,['DIADESEMANA','HORA','FECHA','SERVICIO']]\n",
        "\n",
        "      y_train = train.SERVICIO\n",
        "      X_train = train.drop(labels='SERVICIO', axis=1)\n",
        "\n",
        "      y_test = test.SERVICIO\n",
        "      X_test = test.drop(labels='SERVICIO', axis=1)\n",
        "\n",
        "      '''\n",
        "      if model_type != 'PR':\n",
        "        scaler = PowerTransformer(method='yeo-johnson', standardize=True)\n",
        "        #scaler = StandardScaler()\n",
        "        #scaler = MinMaxScaler(feature_range=(0,1))\n",
        "        #scaler = Normalizer()\n",
        "        scaler.fit(X_train)\n",
        "        X_train = scaler.transform(X_train)\n",
        "        scaler.fit(X_test)\n",
        "        X_test = scaler.transform(X_test)\n",
        "        '''\n",
        "      \n",
        "      if model_type == 'LR':\n",
        "        #Se visualiza los datos\n",
        "        #dataVisualization(train)\n",
        "        model, y_pred, y_prob = lrModel(X_train, y_train, X_test)\n",
        "        #reportClassification(model, X_train, y_train, y_pred, X_test, y_test, model_type)\n",
        "      elif model_type == 'KNN':\n",
        "        model, y_pred, y_prob = knnModel(X_train, y_train, X_test)\n",
        "        #reportClassification(model, X_train, y_train, y_pred, X_test, y_test, model_type)\n",
        "      elif model_type == 'MLP':\n",
        "        model, y_pred, y_prob = mlpModel(X_train, y_train, X_test)\n",
        "        #reportClassification(model, X_train, y_train, y_pred, X_test, y_test, model_type)\n",
        "      elif model_type == 'RFC':\n",
        "        model, y_pred, y_prob = rfcModel(X_train, y_train, X_test)\n",
        "        #reportClassification(model, X_train, y_train, y_pred, X_test, y_test, model_type)\n",
        "      elif model_type == 'SVC':\n",
        "        model, y_pred, y_prob = svcModel(X_train, y_train, X_test)\n",
        "        #reportClassification(model, X_train, y_train, y_pred, X_test, y_test, model_type)\n",
        "      elif model_type == 'SGD':\n",
        "        model, y_pred, y_prob = sgdModel(X_train, y_train, X_test)\n",
        "        #reportClassification(model, X_train, y_train, y_pred, X_test, y_test, model_type)\n",
        "      elif model_type == 'DTC':\n",
        "        model, y_pred, y_prob = dtcModel(X_train, y_train, X_test)\n",
        "        #reportClassification(model, X_train, y_train, y_pred, X_test, y_test, model_type)\n",
        "      elif model_type == 'PR':\n",
        "        #Se caulcula el modelo probabilistico\n",
        "        y_result, y_proba = probabilisticModel(train, date_predict)\n",
        "        \n",
        "        y_result_arr.append(y_result)\n",
        "        y_prob_arr.append(y_proba)\n",
        "        \n",
        "        for i in y_result_arr:\n",
        "          for j in i:\n",
        "            y_pred = np.append(y_pred, int(j))\n",
        "        for i in y_prob_arr:\n",
        "          for j in i:\n",
        "            y_prob = np.append(y_prob, float(j))\n",
        "        class model:\n",
        "          classes_ = np.empty(0,dtype=int)\n",
        "          name = 'Probabilistic'\n",
        "        model.classes_ = np.array([0, 1])\n",
        "        #reportClassification(model, X_train, y_train, y_pred, X_test, y_test, model_type)\n",
        "      else:\n",
        "        print(\"Modelo no existe!\")\n",
        "    #else:\n",
        "    #  print(f\"No hay servicios suficientes para la fecha:{date_predict} del usuario:{phone}!\")\n",
        "  return y_pred, y_test, y_prob"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se crea un nuevo dataFrame con los números de teléfonos para recorrer los modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "total_phone, count, phone_array = 100, 0, []\n",
        "df_phone = df_taxis.loc[:,['TELEFONOORIGEN']].copy()\n",
        "series_phone = df_phone.loc[:,['TELEFONOORIGEN']].value_counts()\n",
        "for phone in series_phone.index.to_list():\n",
        "    if count < total_phone:\n",
        "        count += 1\n",
        "        phone_array.append(phone[0]) \n",
        "#print(phone_array)\n",
        "#series_phone"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluación de los modelos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Experimento con todos los modelos para una semana"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Se quitan los modelos 'LR','SVC','SGD','DTC','MLP' por mal rendimiento\n",
        "models_array = ['PR','KNN','RFC','DTC']#\n",
        "report_models = []\n",
        "roc_curve_arr = []\n",
        "start_proccess = datetime.now()\n",
        "print(f\"Inició el proceso: {datetime.now()}\")\n",
        "for model in models_array:\n",
        "    start_date = datetime.now()\n",
        "    count = 0\n",
        "    kappa_score = 0.0\n",
        "    test_score = 0\n",
        "    confusion_phone = np.matrix(0,dtype=int)\n",
        "    y_test_arr = np.array(0,dtype=int)\n",
        "    y_prob_arr = np.array(0,dtype=float)\n",
        "    for phone in phone_array:\n",
        "        remaining_days = DATE_START_TRAINIG.date() + timedelta(days=7) - DATE_START_TRAINIG.date()\n",
        "        for i in range(remaining_days.days):\n",
        "            last_time = DATE_START_TRAINIG.date() + timedelta(days=i)\n",
        "            y_pred, y_test, y_prob = evaluate_model(phone, df_taxis, pd.to_datetime(last_time, format=FORMAT_DATE), model)\n",
        "            #if(not existAllZero(y_pred)) & (not existAllZero(y_test)):\n",
        "            if len(y_prob)>0:\n",
        "                y_test = y_test.values[:]\n",
        "                y_prob = [y_prob[:, 1] if model != 'PR' else y_prob[:] ]\n",
        "                y_test_arr = np.concatenate((y_test_arr, y_test), axis=None)\n",
        "                y_prob_arr = np.concatenate((y_prob_arr, y_prob), axis=None)\n",
        "            if len(y_pred) > 1:\n",
        "                matrix = np.matrix(confusion_matrix(y_test, y_pred))\n",
        "                if matrix.size == 1:\n",
        "                    matrix = np.matrix([[24,0],[0,0]],dtype=int)\n",
        "                confusion_phone = confusion_phone + matrix\n",
        "                score_k = cohen_kappa_score(y_test, y_pred)\n",
        "                kappa_score += (0.0 if math.isnan (score_k) else score_k)\n",
        "                test_score += np.mean(y_pred == y_test)\n",
        "                count = count + 1\n",
        "                #if(existAllZero(y_pred)) & (existAllZero(y_test)):\n",
        "                #    print(f\"Procesando el teléfono: {phone[0]} y la fecha: {last_time}, confusion: {matrix}, tamanio: {matrix.size}\")\n",
        "                #    print(f\"{y_test} \\n {y_pred} \\n {y_prob}\")\n",
        "            #else:\n",
        "            #    print(f\"Procesando el teléfono: {phone} pero sin predictibilidad\")\n",
        "    roc_curve_arr.append([model, y_test_arr, y_prob_arr])\n",
        "    report_models.append([model,confusion_phone, (kappa_score/count) if kappa_score > 0 else 0, (test_score/count) if test_score > 0 else 0])\n",
        "    print(f\"Procesó el modelo {model} en: {datetime.now()-start_date}\")\n",
        "print(f\"Finalizó el proceso: {datetime.now()} en {datetime.now()-start_proccess}\")\n",
        "#https://scikit-learn.org/stable/modules/generated/sklearn.metrics.RocCurveDisplay.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se ejecuta la matriz de confusión de los modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_array = []\n",
        "for model in report_models:\n",
        "    true_neg = model[1][0,0]\n",
        "    true_pos = model[1][1,1]\n",
        "    false_pos = model[1][0,1]\n",
        "    false_neg = model[1][1,0]\n",
        "    kappa = model[2]\n",
        "    score_test = model[3]\n",
        "\n",
        "    #Precision = TruePositives / (TruePositives + FalsePositives)\n",
        "    precision_scr = true_pos / (true_pos + false_pos) if true_pos > 0 else 0\n",
        "    #Recall = TruePositives / (TruePositives + FalseNegatives)\n",
        "\n",
        "    \n",
        "    recall_scr = true_pos / (true_pos + false_neg) if true_pos > 0 else 0\n",
        "    #F-Measure = (2 * Precision * Recall) / (Precision + Recall)\n",
        "    f1_scr = (2 * precision_scr * recall_scr) / (precision_scr + recall_scr) if true_pos > 0 else 0\n",
        "\n",
        "    #Sacar la tasa de los TP = Que es Positivos del test sobre los positivos predichos\n",
        "    #TP rate = TP / Positivos reales (test)\n",
        "    #FP rate = FP / Negativos reales (test)\n",
        "\n",
        "    models_array.append([modelName(model[0]),\n",
        "                         round(precision_scr,2),\n",
        "                         round(recall_scr,2),\n",
        "                         round(f1_scr,2),\n",
        "                         true_neg,\n",
        "                         true_pos,\n",
        "                         false_pos,\n",
        "                         false_neg,\n",
        "                         round(kappa,2),\n",
        "                         round(score_test,2)])\n",
        "\n",
        "#Mostramos el dataframe con el reporte\n",
        "pd.DataFrame(models_array, columns = ['MODEL','PRECISION','RECALL','F1','TN','TP','FP','FN','KAPPA','SCORE TEST'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Se muestra la curva ROC de los modelos\n",
        "for roc in roc_curve_arr:\n",
        "    if not existAllZero(roc[1]):\n",
        "        ns_probs = [0 for _ in range(len(roc[1]))]\n",
        "        # calculate scores\n",
        "        ns_auc = roc_auc_score(roc[1], ns_probs)\n",
        "        lr_auc = roc_auc_score(roc[1], roc[2])\n",
        "        # summarize scores\n",
        "        \n",
        "        print(f'{modelName(roc[0])}: ROC AUC=%.3f' % (lr_auc))\n",
        "        # calculate roc curves\n",
        "        ns_fpr, ns_tpr, _ = roc_curve(roc[1], ns_probs)\n",
        "        lr_fpr, lr_tpr, _ = roc_curve(roc[1], roc[2])\n",
        "        # plot the roc curve for the model\n",
        "        plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No model')\n",
        "        plt.plot(lr_fpr, lr_tpr, marker='.', label=modelName(roc[0]))\n",
        "        # axis labels\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        # show the legend\n",
        "        plt.legend()\n",
        "        # show the plot\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(f\"El modelo {modelName(roc[0])} no tiene valores para mostrar\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Proyecto predicción servicio taxi.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.2 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "6c66cf74b0d2a9f1f4e9764d44e7ed6418e0349c942d329ab910649654051b15"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
